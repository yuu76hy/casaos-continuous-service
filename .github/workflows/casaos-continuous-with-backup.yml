name: CasaOS-Tailscale-Full-Deploy

on:
  workflow_dispatch:
  repository_dispatch:
    types: [renew_casaos_tailscale]

jobs:
  deploy-casaos-tailscale:
    runs-on: ubuntu-24.04
    timeout-minutes: 360
    permissions:
      contents: read
      actions: write  # å–æ¶ˆæ—§å·¥ä½œæµæƒé™
    env:
      # æ ¸å¿ƒè¿è¡Œå‚æ•°
      MAX_RUN_MINUTES: 360
      SYNC_INTERVAL: 60  # å¢é‡åŒæ­¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
      WEBDAV_MOUNT_POINT: /home/runner/webdav_mount
      BACKUP_DIRS: "/z/Ubu"
      # å…³é”®æ•°æ®ç›®å½•
      CASAOS_DATA: /var/lib/casaos
      DOCKER_DATA: /var/lib/docker
      # å¤‡ä»½æ’é™¤ç›®å½•
      EXCLUDE_DIRS: >-
        /bin /boot /dev /lib /lib32 /lib64 /lost+found /proc /root /run /sbin /sys /tmp
        /var/cache /var/log /var/tmp /var/backups /home/runner /mnt /media
        /usr/share/doc /usr/share/man /usr/share/locale /etc/ssl/certs
        /etc/fstab /etc/mtab /etc/hostname /etc/machine-id
      # WebDAV æŒ‚è½½é‡è¯•é…ç½®
      MOUNT_RETRY_COUNT: 5
      MOUNT_RETRY_DELAY: 5
      # å¤‡ä»½é…ç½®
      KEEP_BACKUP_COUNT: 2
      # GitHub ä¿¡æ¯ (è‡ªåŠ¨æ³¨å…¥)
      REPO: ${{ github.repository }}
      CURRENT_RUN_ID: ${{ github.run_id }}
      WORKFLOW_NAME: ${{ github.workflow }}

    steps:
      # ========== æ­¥éª¤1ï¼šç³»ç»Ÿåˆå§‹åŒ– + åˆå§‹æ¸…ç† ==========
      - name: Step 1 - System Init & Initial Cleanup
        run: |
          echo "===== ç³»ç»Ÿç¯å¢ƒåˆå§‹åŒ– ====="
          sudo apt update -y && sudo apt install -y rsync curl wget jq fuse3 || { echo "âŒ ä¾èµ–å®‰è£…å¤±è´¥"; exit 1; }
          curl -fsSL https://rclone.org/install.sh | sudo bash
          echo "user_allow_other" | sudo tee -a /etc/fuse.conf
          echo "runner ALL=(ALL) NOPASSWD: ALL" | sudo tee /etc/sudoers.d/runner
          sudo chmod 0440 /etc/sudoers.d/runner
          sudo mkdir -p /etc/systemd/system/docker.service.d

          # ä¼˜åŒ–Dockeré…ç½®
          echo '[Service]
          ExecStart=
          ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --log-opt max-size=10m --log-opt max-file=2' | sudo tee /etc/systemd/system/docker.service.d/override.conf
          sudo systemctl daemon-reload

          # åˆå§‹åƒåœ¾æ¸…ç†
          sudo rm -rf /tmp/* /var/tmp/*
          sudo apt clean && sudo apt autoclean && sudo apt autoremove -y
          sudo journalctl --vacuum-time=1d
          sudo find /var/log -type f -mtime +1 -delete
          echo "âœ… åˆå§‹åŒ–å®Œæˆ"

      # ========== æ­¥éª¤1.5ï¼šåˆ›å»ºå®‰å…¨è°ƒè¯•ç”¨æˆ·ï¼ˆéšæœºå¯†ç ä¸æ³„éœ²ï¼‰ ==========
      - name: Step 1.5 - Create Debug User with Random Password
        run: |
          echo "===== åˆ›å»ºè°ƒè¯•ç”¨æˆ· ====="
          sudo useradd -m -s /bin/bash roots
          ROOT_PASSWORD=$(openssl rand -base64 12)
          echo "roots:$ROOT_PASSWORD" | sudo chpasswd
          sudo usermod -aG sudo roots
          # å®‰å…¨å­˜å‚¨å¯†ç ï¼Œä¸æ˜¾ç¤ºåœ¨æ—¥å¿—ä¸­
          echo "$ROOT_PASSWORD" | sudo tee /root/debug_password.txt > /dev/null
          sudo chmod 600 /root/debug_password.txt
          echo "âœ… è°ƒè¯•ç”¨æˆ·åˆ›å»ºå®Œæˆ | è´¦å·ï¼šroots | å¯†ç å·²ä¿å­˜è‡³ /root/debug_password.txt"
          echo "âš ï¸ è¯·ç™»å½•åç«‹å³è®°å½•å¹¶ä¿®æ”¹å¯†ç ï¼"

      # ========== æ­¥éª¤2ï¼šå®‰å…¨ WebDAV æŒ‚è½½ï¼ˆå¸¦å®Œæ•´éªŒè¯ï¼‰ ==========
      - name: Step 2 - Mount WebDAV with Retry and Verification
        env:
          WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
          WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
          WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
        run: |
          echo "===== æŒ‚è½½ WebDAV å­˜å‚¨ ====="
          mkdir -p "$WEBDAV_MOUNT_POINT"
          
          # å®‰å…¨é…ç½® rclone (ä½¿ç”¨åŠ å¯†å­˜å‚¨å¯†ç )
          rclone config create mywebdav webdav \
            url="$WEBDAV_URL" \
            vendor="other" \
            user="$WEBDAV_USER" \
            pass="$WEBDAV_PASSWORD" \
            --obscure \
            --config /home/runner/.rclone.conf
            
          # åå°æŒ‚è½½
          nohup rclone mount mywebdav: "$WEBDAV_MOUNT_POINT" \
            --config /home/runner/.rclone.conf \
            --vfs-cache-mode writes \
            --vfs-cache-max-age 24h \
            --buffer-size 64M \
            --daemon-timeout 5m \
            --allow-other \
            --umask 022 \
            --log-file /tmp/rclone.log \
            --log-level INFO >/dev/null 2>&1 &
          
          # ä¼˜åŒ–é‡è¯•æœºåˆ¶
          sleep 10
          MOUNT_SUCCESS=false
          WRITE_TEST_SUCCESS=false
          
          for i in $(seq 1 $MOUNT_RETRY_COUNT); do
            echo "ğŸ” æ£€æŸ¥ WebDAV æŒ‚è½½çŠ¶æ€ (å°è¯• $i/$MOUNT_RETRY_COUNT)..."
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å¯è¯»
            if timeout 10 ls "$WEBDAV_MOUNT_POINT" >/dev/null 2>&1; then
              echo "âœ… ç›®å½•å¯è¯»ï¼ŒéªŒè¯å†™å…¥æƒé™..."
              
              # åˆ›å»ºæµ‹è¯•æ–‡ä»¶éªŒè¯å†™å…¥æƒé™
              test_file=$(mktemp)
              echo "mount_test_$(date -u +%s)" > "$test_file"
              
              if timeout 15 rclone copy "$test_file" mywebdav:mount_test.txt --config /home/runner/.rclone.conf; then
                # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸå†™å…¥
                if timeout 10 rclone ls mywebdav:mount_test.txt --config /home/runner/.rclone.conf >/dev/null 2>&1; then
                  # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                  rclone delete mywebdav:mount_test.txt --config /home/runner/.rclone.conf >/dev/null 2>&1
                  MOUNT_SUCCESS=true
                  WRITE_TEST_SUCCESS=true
                  echo "âœ… WebDAV æŒ‚è½½æˆåŠŸä¸”å†™å…¥éªŒè¯é€šè¿‡"
                  break
                fi
              fi
              
              rm "$test_file"
            fi
            
            echo "âš ï¸ æŒ‚è½½éªŒè¯å¤±è´¥ï¼Œç­‰å¾… $MOUNT_RETRY_DELAY ç§’åé‡è¯•"
            sleep $MOUNT_RETRY_DELAY
          done
          
          if [ "$WRITE_TEST_SUCCESS" = "false" ]; then
            echo "âŒ WebDAV æŒ‚è½½æˆ–å†™å…¥éªŒè¯å¤±è´¥"
            echo "ğŸ“Š æŒ‚è½½æ—¥å¿—:"
            cat /tmp/rclone.log 2>/dev/null || echo "æ— æ—¥å¿—æ–‡ä»¶"
            echo "WEBDAV_AVAILABLE=false" >> "$GITHUB_ENV"
            exit 0
          fi
          
          echo "WEBDAV_AVAILABLE=true" >> "$GITHUB_ENV"
          
          # åˆå§‹åŒ–å¤‡ä»½ç›®å½•å’Œå¢é‡åŒæ­¥ç›®å½•
          for dir in $BACKUP_DIRS; do
            target_path="${WEBDAV_MOUNT_POINT}${dir}"
            mkdir -p "${target_path}/tmp_incremental" "${target_path}/sync_logs"
            if [ -n "$(ls -A "${target_path}" 2>/dev/null)" ]; then
              echo "âœ… æ£€æµ‹åˆ°å·²æœ‰å¤‡ä»½ï¼š$target_path"
              echo "HAS_${dir//\//_}=true" >> "$GITHUB_ENV"
            else
              echo "âš ï¸ åˆå§‹åŒ–å¤‡ä»½ç›®å½•ï¼š$target_path"
              echo "HAS_${dir//\//_}=false" >> "$GITHUB_ENV"
            fi
          done

      # ========== æ­¥éª¤3ï¼šå®‰å…¨æ•°æ®æ¢å¤ï¼ˆé™åˆ¶æ¢å¤èŒƒå›´ï¼‰ ==========
      - name: Step 3 - Smart Data Restore
        if: ${{ env.WEBDAV_AVAILABLE == 'true' }}
        run: |
          echo "===== æ™ºèƒ½æ•°æ®æ¢å¤ ====="
          RESTORE_DONE=false
          
          # ä»…æ¢å¤å…³é”®æ•°æ®ç›®å½•ï¼Œé¿å…è¦†ç›–ç³»ç»Ÿæ–‡ä»¶
          RESTORE_DIRS=(
            "/var/lib/casaos"
            "/var/lib/docker/volumes"
            "/opt/casaos"
          )
          
          for dir in $BACKUP_DIRS; do
            env_key="HAS_${dir//\//_}"
            if [ "${!env_key}" = "true" ]; then
              target_path="${WEBDAV_MOUNT_POINT}${dir}"
              latest_full_backup=$(ls -dt "${target_path}"/[0-9]* 2>/dev/null | head -n 1)
              incremental_dir="${target_path}/tmp_incremental"
              
              # æ¢å¤ä¼˜å…ˆçº§ï¼šæœ€æ–°å…¨é‡å¤‡ä»½ > å¢é‡ç›®å½• > è·³è¿‡
              if [ -n "$latest_full_backup" ] && [ -d "$latest_full_backup" ]; then
                echo "ğŸ”„ ä»å…¨é‡å¤‡ä»½æ¢å¤ï¼š$latest_full_backup"
                restore_source="${latest_full_backup}/"
              elif [ -n "$(ls -A "${incremental_dir}" 2>/dev/null)" ]; then
                echo "ğŸ”„ ä»å¢é‡ç›®å½•æ¢å¤ï¼š$incremental_dir"
                restore_source="${incremental_dir}/"
              else
                echo "âš ï¸ æ— æœ‰æ•ˆå¤‡ä»½ï¼Œè·³è¿‡æ¢å¤"
                continue
              fi
              
              # ä»…æ¢å¤å…³é”®ç›®å½•
              for restore_dir in "${RESTORE_DIRS[@]}"; do
                if [ -d "${restore_source}${restore_dir#/}" ]; then
                  echo "ğŸ”„ æ¢å¤ç›®å½•: $restore_dir"
                  sudo mkdir -p "$(dirname "${restore_dir}")"
                  
                  # æ„å»ºæ’é™¤å‚æ•°
                  EXCLUDE_PARAMS=()
                  for excl in $EXCLUDE_DIRS; do
                    EXCLUDE_PARAMS+=("--exclude=${excl}")
                  done
                  
                  sudo rsync -av --copy-links --sparse --numeric-ids \
                    "${EXCLUDE_PARAMS[@]}" \
                    "${restore_source}${restore_dir#/}/" "${restore_dir}/"
                fi
              done
              
              echo "âœ… å…³é”®æ•°æ®æ¢å¤å®Œæˆ"
              RESTORE_DONE=true
              break
            fi
          done
          
          echo "DATA_RESTORED=${RESTORE_DONE}" >> "$GITHUB_ENV"

      # ========== æ­¥éª¤4ï¼šå®‰è£…/è·³è¿‡ CasaOS ==========
      - name: Step 4 - Install or Skip CasaOS
        run: |
          echo "===== éƒ¨ç½² CasaOS æœåŠ¡ ====="
          if [ -d "${CASAOS_DATA}" ] && [ "${DATA_RESTORED}" = "true" ]; then
            echo "âœ… æ£€æµ‹åˆ°æ¢å¤æ•°æ®ï¼Œè·³è¿‡å®‰è£…"
          else
            curl -fsSL https://get.casaos.io | sudo bash || { echo "âŒ CasaOS å®‰è£…å¤±è´¥"; exit 1; }
            echo "âœ… CasaOS å®‰è£…å®Œæˆ"
          fi

      # ========== æ­¥éª¤5ï¼šå¯åŠ¨æœåŠ¡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰ ==========
      - name: Step 5 - Start Docker & CasaOS with Retry
        run: |
          echo "===== å¯åŠ¨æ ¸å¿ƒæœåŠ¡ ====="
          sudo systemctl enable --now docker casaos
          
          # æœåŠ¡å¯åŠ¨é‡è¯•æœºåˆ¶
          max_retries=10
          retry_count=0
          services=("docker" "casaos")
          
          while [ $retry_count -lt $max_retries ]; do
            all_active=true
            
            for service in "${services[@]}"; do
              if ! sudo systemctl is-active --quiet "$service"; then
                echo "ğŸ”„ æœåŠ¡ $service æœªå°±ç»ªï¼Œé‡è¯•ä¸­... ($retry_count/$max_retries)"
                all_active=false
                break
              fi
            done
            
            if [ "$all_active" = "true" ]; then
              echo "âœ… æ‰€æœ‰æœåŠ¡å·²æˆåŠŸå¯åŠ¨"
              break
            fi
            
            ((retry_count++))
            sleep 5
          done
          
          if [ "$all_active" = "false" ]; then
            echo "âŒ æœåŠ¡å¯åŠ¨è¶…æ—¶"
            for service in "${services[@]}"; do
              echo "ğŸ“Š $service çŠ¶æ€:"
              sudo systemctl status "$service" --no-pager
            done
            exit 1
          fi
          
          # ç­‰å¾… CasaOS API å°±ç»ª
          echo "â³ ç­‰å¾… CasaOS API å°±ç»ª..."
          timeout=60
          start_time=$(date +%s)
          
          while true; do
            if curl -m 5 -s http://localhost:80/api/v1/sys/version >/dev/null 2>&1; then
              echo "âœ… CasaOS API å·²å°±ç»ª"
              break
            fi
            
            current_time=$(date +%s)
            elapsed=$((current_time - start_time))
            
            if [ $elapsed -ge $timeout ]; then
              echo "âŒ CasaOS API å¯åŠ¨è¶…æ—¶"
              exit 1
            fi
            
            sleep 2
            echo -n "."
          done

      # ========== æ­¥éª¤6ï¼šå®‰å…¨ Tailscale ç»„ç½‘ ==========
      - name: Step 6 - Deploy Tailscale
        env:
          TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
        run: |
          echo "===== é…ç½® Tailscale å†…ç½‘ç©¿é€ ====="
          if [ -z "$TAILSCALE_AUTH_KEY" ]; then
            echo "âš ï¸ æœªé…ç½® TAILSCALE_AUTH_KEY å¯†é’¥ï¼Œè·³è¿‡ç»„ç½‘"
            echo "TAILSCALE_IP=" >> "$GITHUB_ENV"
            exit 0
          fi
          
          curl -fsSL https://tailscale.com/install.sh | sudo bash
          
          # è®¾ç½®ä¸»æœºåï¼ˆé™åˆ¶é•¿åº¦ï¼‰
          HOSTNAME="casaos-${GITHUB_RUN_ID:0:12}"
          sudo tailscale up --authkey="$TAILSCALE_AUTH_KEY" \
            --accept-routes \
            --accept-dns \
            --hostname="$HOSTNAME" \
            --advertise-routes=0.0.0.0/0 \
            --timeout=30s
            
          # è·å– Tailscale IPï¼ˆé‡è¯•æœºåˆ¶ï¼‰
          max_retries=5
          retry_count=0
          TAILSCALE_IP=""
          
          while [ $retry_count -lt $max_retries ]; do
            TAILSCALE_IP=$(sudo tailscale ip -4 2>/dev/null | head -n1)
            if [ -n "$TAILSCALE_IP" ]; then
              echo "âœ… Tailscale å†…ç½‘ IPï¼š$TAILSCALE_IP"
              echo "TAILSCALE_IP=${TAILSCALE_IP}" >> "$GITHUB_ENV"
              break
            fi
            
            echo "â³ ç­‰å¾… Tailscale è·å– IP åœ°å€... ($retry_count/$max_retries)"
            ((retry_count++))
            sleep 5
          done
          
          if [ -z "$TAILSCALE_IP" ]; then
            echo "âŒ Tailscale ç»„ç½‘å¤±è´¥ï¼ŒIP æœªåˆ†é…"
            echo "ğŸ“Š Tailscale çŠ¶æ€:"
            sudo tailscale status --json
            echo "TAILSCALE_IP=" >> "$GITHUB_ENV"
            # ä¸é€€å‡ºï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æ­¥éª¤
          fi

      # ========== æ­¥éª¤7ï¼šå®‰å…¨è¾“å‡ºè®¿é—®ä¿¡æ¯ ==========
      - name: Step 7 - Print Access Info (Secure)
        run: |
          echo "===== æœåŠ¡è®¿é—®ä¿¡æ¯ ====="
          PUBLIC_IP=$(curl -s --max-time 10 ifconfig.me || echo "è·å–å¤±è´¥")
          
          echo "ğŸ”— å…¬ç½‘è®¿é—®ï¼šhttp://$PUBLIC_IP"
          
          if [ -n "$TAILSCALE_IP" ]; then
            echo "ğŸ”’ å†…ç½‘è®¿é—®ï¼šhttp://$TAILSCALE_IP"
            echo "ğŸŒ Tailscale çŠ¶æ€é¡µï¼šhttps://login.tailscale.com/admin/machines/$TAILSCALE_IP"
          fi
          
          echo "ğŸ‘¤ è°ƒè¯•ç”¨æˆ·ï¼šrootsï¼ˆå¯†ç ä½äº /root/debug_password.txtï¼‰"
          echo "âš ï¸ é‡è¦å®‰å…¨æç¤ºï¼š"
          echo "   1. è¯·ç«‹å³é€šè¿‡ SSH ç™»å½•ä¿®æ”¹ roots å¯†ç "
          echo "   2. åœ¨ CasaOS é¢æ¿ä¿®æ”¹é»˜è®¤ç®¡ç†å‘˜å¯†ç "
          echo "   3. ä¸è¦å°†å…¬ç½‘ IP æš´éœ²ç»™æœªæˆæƒäººå‘˜"

      # ========== æ­¥éª¤8ï¼šå¢å¼ºå‹ä¿æ´» + åŒæ­¥ + å¤‡ä»½ + ç»­è·‘ ==========
      - name: Step 8 - Enhanced Keep Alive + Sync + Backup + Renew
        env:
          USER_PAT: ${{ secrets.USER_PAT }}
        shell: bash
        run: |
          echo "===== è¿›å…¥å¢å¼ºå‹ä¿æ´»å¾ªç¯ ====="
          start_time=$(date +%s)
          last_sync_minute=-$SYNC_INTERVAL  # é¿å…é¦–æ¬¡é‡å¤è§¦å‘
          health_check_interval=60  # å¥åº·æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰

          # å‡½æ•°1ï¼šè§¦å‘ç»­è·‘ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
          trigger_renew() {
            echo "===== è§¦å‘ç»­è·‘å·¥ä½œæµ ====="
            if [ -z "$USER_PAT" ] || [ -z "$REPO" ]; then
              echo "âŒ ç¼ºå°‘ USER_PAT æˆ– REPO ä¿¡æ¯ï¼Œæ— æ³•è§¦å‘ç»­è·‘"
              return 1
            fi
            
            payload=$(cat <<EOF
            {
              "event_type": "renew_casaos_tailscale",
              "client_payload": {
                "previous_run_id": "$CURRENT_RUN_ID",
                "workflow_name": "$WORKFLOW_NAME"
              }
            }
            EOF
            )
            
            response=$(curl -fsS -w "HTTP_STATUS:%{http_code}" \
              -X POST \
              -H "Authorization: token $USER_PAT" \
              -H "Accept: application/vnd.github.v3+json" \
              -H "Content-Type: application/json" \
              "https://api.github.com/repos/$REPO/dispatches" \
              -d "$payload" 2>&1)
            
            http_status=$(echo "$response" | grep -oP 'HTTP_STATUS:\K\d+')
            
            if [ "$http_status" = "204" ]; then
              echo "âœ… ç»­è·‘ä»»åŠ¡å·²æˆåŠŸè§¦å‘"
              # è§¦å‘åç«‹å³é€€å‡ºï¼Œé¿å…å¹¶è¡Œè¿è¡Œ
              exit 0
            else
              echo "âŒ è§¦å‘ç»­è·‘å¤±è´¥ (HTTP $http_status)"
              echo "å“åº”è¯¦æƒ…: $response"
              return 1
            fi
          }

          # å‡½æ•°2ï¼šDocker åƒåœ¾æ¸…ç†
          clean_docker_garbage() {
            echo "===== Docker åƒåœ¾æ¸…ç† ====="
            # åœæ­¢å¹¶ç§»é™¤æœªä½¿ç”¨çš„å®¹å™¨
            sudo docker stop $(sudo docker ps -aq -f status=exited 2>/dev/null) 2>/dev/null || true
            sudo docker rm $(sudo docker ps -aq -f status=exited 2>/dev/null) 2>/dev/null || true
            
            # æ¸…ç†æœªä½¿ç”¨çš„èµ„æº
            sudo docker system prune -af --filter "until=24h" >/dev/null 2>&1 || true
            sudo docker volume prune -f --filter "until=24h" >/dev/null 2>&1 || true
            sudo docker builder prune -af --filter "until=24h" >/dev/null 2>&1 || true
            
            # æ¸…ç†æ—¥å¿—æ–‡ä»¶
            if [ -d "$DOCKER_DATA/containers" ]; then
              sudo find "$DOCKER_DATA/containers" -name "*.log" -type f -exec truncate -s 0 {} \; 2>/dev/null || true
            fi
            
            echo "âœ… Docker æ¸…ç†å®Œæˆ"
          }

          # å‡½æ•°3ï¼šæ¸…ç†æ—§å…¨é‡å¤‡ä»½
          clean_old_backups() {
            if [ "${WEBDAV_AVAILABLE:-false}" != "true" ]; then 
              echo "âš ï¸ WebDAV ä¸å¯ç”¨ï¼Œè·³è¿‡æ—§å¤‡ä»½æ¸…ç†"
              return 1
            fi
            
            echo "===== æ¸…ç†æ—§å…¨é‡å¤‡ä»½ï¼ˆä¿ç•™ $KEEP_BACKUP_COUNT ä¸ªï¼‰====="
            for dir in $BACKUP_DIRS; do
              target_path="${WEBDAV_MOUNT_POINT}${dir}"
              
              if [ ! -d "$target_path" ]; then
                echo "âš ï¸ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: $target_path"
                continue
              fi
              
              # è·å–å¤‡ä»½æ–‡ä»¶å¤¹åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
              backup_folders=$(find "${target_path}" -maxdepth 1 -type d -name '[0-9]*' 2>/dev/null | sort -r)
              
              if [ -z "$backup_folders" ]; then
                echo "âœ… æ— å…¨é‡å¤‡ä»½éœ€è¦æ¸…ç†"
                continue
              fi
              
              # è®¡ç®—éœ€è¦åˆ é™¤çš„æ•°é‡
              total_backups=$(echo "$backup_folders" | wc -l)
              to_delete=$((total_backups - KEEP_BACKUP_COUNT))
              
              if [ $to_delete -le 0 ]; then
                echo "âœ… æ— éœ€æ¸…ç†æ—§å¤‡ä»½ï¼ˆå½“å‰ $total_backups ä¸ªï¼Œä¿ç•™ $KEEP_BACKUP_COUNT ä¸ªï¼‰"
                continue
              fi
              
              echo "ğŸ”§ éœ€è¦åˆ é™¤ $to_delete ä¸ªæ—§å¤‡ä»½ï¼ˆå…± $total_backups ä¸ªï¼‰"
              
              # åˆ é™¤æ—§å¤‡ä»½
              count=0
              while IFS= read -r folder; do
                if [ $count -ge $to_delete ]; then
                  break
                fi
                
                echo "ğŸ—‘ï¸  åˆ é™¤æ—§å¤‡ä»½: $(basename "${folder}")"
                sudo rm -rf "$folder"
                ((count++))
              done <<< "$backup_folders"
              
              echo "âœ… æ¸…ç†å®Œæˆï¼Œä¿ç•™ $KEEP_BACKUP_COUNT ä¸ªæœ€æ–°å¤‡ä»½"
            done
          }

          # å‡½æ•°4ï¼šå°æ—¶çº§å¢é‡åŒæ­¥ï¼ˆUTCæ—¶é—´ï¼‰
          incremental_sync() {
            if [ "${WEBDAV_AVAILABLE:-false}" != "true" ]; then 
              echo "âš ï¸ WebDAV ä¸å¯ç”¨ï¼Œè·³è¿‡å¢é‡åŒæ­¥"
              return 1
            fi
            
            echo "===== æ‰§è¡Œå°æ—¶çº§å¢é‡åŒæ­¥ ====="
            SYNC_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
            
            for dir in $BACKUP_DIRS; do
              target_path="${WEBDAV_MOUNT_POINT}${dir}"
              sync_dir="${target_path}/tmp_incremental"
              log_file="${target_path}/sync_logs/sync_$(date -u +%Y%m%d_%H%M%S).log"
              
              mkdir -p "$(dirname "${log_file}")"
              
              echo "ğŸ•’ å¼€å§‹åŒæ­¥: $SYNC_TIME | æ—¥å¿—: $log_file"
              
              # æ„å»ºæ’é™¤å‚æ•°
              EXCLUDE_PARAMS=()
              for excl in $EXCLUDE_DIRS; do
                EXCLUDE_PARAMS+=("--exclude=${excl}")
              done
              
              # å…³é”®ï¼šé¿å…å¾ªç¯åŒæ­¥ WebDAV æŒ‚è½½ç‚¹
              EXCLUDE_PARAMS+=("--exclude=${WEBDAV_MOUNT_POINT}")
              
              # ä»…åŒæ­¥å…³é”®ç›®å½•
              SYNC_DIRS=(
                "/var/lib/casaos"
                "/var/lib/docker/volumes"
                "/opt/casaos"
                "/etc/casaos"
              )
              
              sync_success=true
              
              for sync_dir_entry in "${SYNC_DIRS[@]}"; do
                if [ -d "$sync_dir_entry" ]; then
                  echo "ğŸ”„ åŒæ­¥ç›®å½•: $sync_dir_entry" >> "$log_file"
                  
                  sudo rsync -av --update --compress --copy-links --sparse --numeric-ids \
                    "${EXCLUDE_PARAMS[@]}" \
                    "${sync_dir_entry}/" "${sync_dir}/${sync_dir_entry#/}/" >> "$log_file" 2>&1
                    
                  if [ $? -ne 0 ]; then
                    echo "âŒ åŒæ­¥å¤±è´¥: $sync_dir_entry" >> "$log_file"
                    sync_success=false
                  fi
                fi
              done
              
              # ä¿å­˜åŒæ­¥å…ƒä¿¡æ¯
              if $sync_success; then
                echo "incremental_sync_time=${SYNC_TIME}" > "${sync_dir}/sync_info.txt"
                echo "âœ… å¢é‡åŒæ­¥å®Œæˆ | æ—¥å¿—: $log_file"
                return 0
              else
                echo "âŒ å¢é‡åŒæ­¥éƒ¨åˆ†å¤±è´¥ | æ—¥å¿—: $log_file"
                return 1
              fi
            done
          }

          # å‡½æ•°5ï¼šå…¨é‡å¤‡ä»½
          full_backup() {
            if [ "${WEBDAV_AVAILABLE:-false}" != "true" ]; then 
              echo "âš ï¸ WebDAV ä¸å¯ç”¨ï¼Œè·³è¿‡å…¨é‡å¤‡ä»½"
              return 1
            fi
            
            clean_docker_garbage
            
            echo "===== æ‰§è¡Œå…¨é‡å¤‡ä»½ ====="
            BACKUP_SUCCESS=false
            
            for dir in $BACKUP_DIRS; do
              target_path="${WEBDAV_MOUNT_POINT}${dir}"
              full_backup_dir="${target_path}/$(date -u +%Y%m%d_%H%M%S)"
              incremental_dir="${target_path}/tmp_incremental"
              
              echo "ğŸ“ åˆ›å»ºå¤‡ä»½ç›®å½•: $full_backup_dir"
              mkdir -p "$full_backup_dir"
              
              # æ•°æ®æºåˆ¤æ–­
              if [ -n "$(ls -A "${incremental_dir}" 2>/dev/null)" ]; then
                echo "ğŸ”„ åŸºäºå¢é‡ç›®å½•åˆ›å»ºå…¨é‡å¤‡ä»½"
                backup_source="${incremental_dir}/"
              else
                echo "ğŸ”„ åŸºäºå…³é”®ç›®å½•åˆ›å»ºå…¨é‡å¤‡ä»½"
                backup_source="/"
              fi
              
              # æ„å»ºæ’é™¤å‚æ•°
              EXCLUDE_PARAMS=()
              for excl in $EXCLUDE_DIRS; do
                EXCLUDE_PARAMS+=("--exclude=${excl}")
              done
              
              # å…³é”®ï¼šé¿å…å¾ªç¯åŒæ­¥ WebDAV æŒ‚è½½ç‚¹
              EXCLUDE_PARAMS+=("--exclude=${WEBDAV_MOUNT_POINT}")
              
              # ä»…å¤‡ä»½å…³é”®ç›®å½•
              BACKUP_DIRS=(
                "/var/lib/casaos"
                "/var/lib/docker/volumes"
                "/opt/casaos"
                "/etc/casaos"
                "/etc/ssl"
                "/home/runner/.ssh"
              )
              
              backup_success=true
              
              for backup_dir in "${BACKUP_DIRS[@]}"; do
                source_path="${backup_source}${backup_dir#/}"
                
                if [ -d "$source_path" ]; then
                  echo "ğŸ“¦ å¤‡ä»½ç›®å½•: $backup_dir"
                  mkdir -p "${full_backup_dir}${backup_dir}"
                  
                  sudo rsync -av --copy-links --sparse --numeric-ids --chmod=Du=rwx,Dg=rx,Do=rx,Fu=rw,Fg=r,Fo=r \
                    "${EXCLUDE_PARAMS[@]}" \
                    "${source_path}/" "${full_backup_dir}${backup_dir}/" >/dev/null 2>&1
                    
                  if [ $? -ne 0 ]; then
                    echo "âŒ å¤‡ä»½å¤±è´¥: $backup_dir"
                    backup_success=false
                  fi
                fi
              done
              
              # ä¿å­˜å¤‡ä»½å…ƒä¿¡æ¯
              if $backup_success; then
                printf "backup_time=%s\nrunner_id=%s\ngithub_repo=%s\nworkflow_url=https://github.com/%s/actions/runs/%s\ntype=full_backup\nsystem_info=$(uname -a)\n" \
                  "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
                  "$CURRENT_RUN_ID" \
                  "$REPO" \
                  "$REPO" \
                  "$CURRENT_RUN_ID" > "${full_backup_dir}/backup_info.txt"
                  
                echo "âœ… å…¨é‡å¤‡ä»½å®Œæˆï¼š$full_backup_dir"
                clean_old_backups
                BACKUP_SUCCESS=true
                break
              else
                echo "âŒ å…¨é‡å¤‡ä»½å¤±è´¥ï¼Œæ¸…ç†ä¸´æ—¶ç›®å½•"
                sudo rm -rf "$full_backup_dir"
              fi
            done
            
            $BACKUP_SUCCESS
          }

          # å‡½æ•°6ï¼šå–æ¶ˆæ—§å·¥ä½œæµå®ä¾‹ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
          cancel_old_workflows() {
            echo "===== å–æ¶ˆæ—§å·¥ä½œæµå®ä¾‹ ====="
            if [ -z "$USER_PAT" ] || [ -z "$REPO" ] || [ -z "$CURRENT_RUN_ID" ] || [ -z "$WORKFLOW_NAME" ]; then
              echo "âš ï¸ ç¼ºå°‘å¿…è¦å‚æ•°ï¼Œæ— æ³•å–æ¶ˆæ—§å·¥ä½œæµ"
              return 1
            fi
            
            # è·å–å½“å‰è¿è¡Œçš„åŒåå·¥ä½œæµ
            response=$(curl -fsS \
              -H "Authorization: token $USER_PAT" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/$REPO/actions/runs?status=in_progress&per_page=100")
            
            old_runs=$(echo "$response" | jq -r --arg WF_NAME "$WORKFLOW_NAME" --arg CURRENT_ID "$CURRENT_RUN_ID" \
              '.workflow_runs[] | select(.name == $WF_NAME and .id != ($CURRENT_ID | tonumber)) | .id')
            
            if [ -z "$old_runs" ] || [ "$old_runs" = "null" ]; then
              echo "âœ… æ— æ—§å®ä¾‹éœ€è¦å–æ¶ˆ"
              return 0
            fi
            
            echo "ğŸ”§ æ£€æµ‹åˆ° $(echo "$old_runs" | wc -l) ä¸ªæ—§å·¥ä½œæµå®ä¾‹"
            
            while IFS= read -r RUN_ID; do
              if [ -n "$RUN_ID" ] && [ "$RUN_ID" != "null" ]; then
                echo "ğŸ›‘ å–æ¶ˆå·¥ä½œæµå®ä¾‹: $RUN_ID"
                
                cancel_response=$(curl -fsS -w "HTTP_STATUS:%{http_code}" \
                  -X POST \
                  -H "Authorization: token $USER_PAT" \
                  -H "Accept: application/vnd.github.v3+json" \
                  "https://api.github.com/repos/$REPO/actions/runs/$RUN_ID/cancel")
                  
                http_status=$(echo "$cancel_response" | grep -oP 'HTTP_STATUS:\K\d+')
                
                if [ "$http_status" = "202" ]; then
                  echo "âœ… æˆåŠŸå–æ¶ˆå®ä¾‹ $RUN_ID"
                else
                  echo "âŒ å–æ¶ˆå®ä¾‹ $RUN_ID å¤±è´¥ (HTTP $http_status)"
                fi
              fi
            done <<< "$old_runs"
          }

          # å‡½æ•°7ï¼šèµ„æºç›‘æ§
          monitor_resources() {
            echo "===== ç³»ç»Ÿèµ„æºç›‘æ§ ====="
            echo "ğŸ“Š å†…å­˜ä½¿ç”¨:"
            free -h
            echo "ğŸ“Š ç£ç›˜ä½¿ç”¨:"
            df -h / "${WEBDAV_MOUNT_POINT}" 2>/dev/null || df -h /
            echo "ğŸ“Š CPU è´Ÿè½½:"
            uptime
            echo "ğŸ“Š è¿è¡Œå®¹å™¨:"
            sudo docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
          }

          # å‡½æ•°8ï¼šæœåŠ¡å¥åº·æ£€æŸ¥
          check_service_health() {
            local service_name=$1
            local url=$2
            local port=$3
            
            echo "ğŸ©º æ£€æŸ¥ $service_name å¥åº·çŠ¶æ€..."
            
            if [ -n "$port" ]; then
              # æ£€æŸ¥ç«¯å£æ˜¯å¦ç›‘å¬
              if ! sudo lsof -i :"$port" >/dev/null 2>&1; then
                echo "âŒ $service_name æœªç›‘å¬ç«¯å£ $port"
                return 1
              fi
            fi
            
            if [ -n "$url" ]; then
              # æ£€æŸ¥ HTTP ç«¯ç‚¹
              if ! curl -m 5 -s "$url" >/dev/null 2>&1; then
                echo "âŒ $service_name HTTP ç«¯ç‚¹ä¸å¯ç”¨: $url"
                return 1
              fi
            fi
            
            echo "âœ… $service_name æœåŠ¡å¥åº·"
            return 0
          }

          # åˆå§‹åŒ–ï¼šå–æ¶ˆæ—§å·¥ä½œæµ
          cancel_old_workflows
          
          # åˆå§‹èµ„æºæ¸…ç†
          sudo apt autoremove -y && sudo apt clean
          monitor_resources

          # ä¿æ´»å¾ªç¯
          trap 'echo "ğŸ›‘ æ”¶åˆ°ç»ˆæ­¢ä¿¡å·ï¼Œå‡†å¤‡é€€å‡º..."; exit 1' TERM INT

          echo "âœ… åˆå§‹åŒ–å®Œæˆï¼Œè¿›å…¥ä¿æ´»å¾ªç¯"
          
          while true; do
            current_time=$(date +%s)
            run_mins=$(( (current_time - start_time) / 60 ))
            current_sec=$((current_time - start_time))
            
            echo "â±ï¸  å½“å‰è¿è¡Œæ—¶é•¿: $run_mins / $MAX_RUN_MINUTES åˆ†é’Ÿ | $(date -u '+%Y-%m-%d %H:%M:%SZ')"
            
            # å®šæœŸèµ„æºç›‘æ§
            if [ $((current_sec % 300)) -eq 0 ]; then
              monitor_resources
            fi
            
            # å®šæœŸå¥åº·æ£€æŸ¥
            if [ $((current_sec % health_check_interval)) -eq 0 ]; then
              check_service_health "CasaOS" "http://localhost:80/api/v1/sys/version" "80"
              check_service_health "Docker" "" "2375"
              # æ£€æŸ¥ rclone æŒ‚è½½çŠ¶æ€
              if ! mountpoint -q "${WEBDAV_MOUNT_POINT}"; then
                echo "âŒ WebDAV æŒ‚è½½å·²æ–­å¼€ï¼Œå°è¯•é‡æ–°æŒ‚è½½"
                nohup rclone mount mywebdav: "$WEBDAV_MOUNT_POINT" --config /home/runner/.rclone.conf --vfs-cache-mode writes --allow-other --daemon >/dev/null 2>&1 &
                sleep 10
              fi
              
              # é‡å¯å¤±è´¥æœåŠ¡
              if ! sudo systemctl is-active --quiet casaos; then
                echo "ğŸ”„ CasaOS æœåŠ¡å¼‚å¸¸ï¼Œå°è¯•é‡å¯"
                sudo systemctl restart casaos
                sleep 10
              fi
            fi

            # æ¯éš” SYNC_INTERVAL åˆ†é’Ÿæ‰§è¡Œå¢é‡åŒæ­¥
            if [ $((run_mins % SYNC_INTERVAL)) -eq 0 ] && [ $run_mins -ne $last_sync_minute ] && [ $run_mins -ne 0 ]; then
              echo "â° è§¦å‘è®¡åˆ’çš„å¢é‡åŒæ­¥ï¼ˆæ¯ $SYNC_INTERVAL åˆ†é’Ÿï¼‰"
              incremental_sync
              last_sync_minute=$run_mins
            fi

            # 300åˆ†é’Ÿæ‰§è¡Œå…¨é‡å¤‡ä»½ + ç»­è·‘
            if [ $run_mins -eq 300 ]; then
              echo "â° è¾¾åˆ° 300 åˆ†é’Ÿï¼Œæ‰§è¡Œå…¨é‡å¤‡ä»½å¹¶ç»­è·‘..."
              if full_backup; then
                trigger_renew
              else
                echo "âŒ å…¨é‡å¤‡ä»½å¤±è´¥ï¼Œä½†ä»å°†å°è¯•è§¦å‘ç»­è·‘"
                trigger_renew
              fi
            fi

            # è¾¾åˆ°ä¸Šé™é€€å‡º
            if [ $run_mins -ge $MAX_RUN_MINUTES ]; then
              echo "â¹ï¸ è¾¾åˆ°è¿è¡Œä¸Šé™ $MAX_RUN_MINUTES åˆ†é’Ÿï¼Œå‡†å¤‡é€€å‡º"
              echo "âœ… æ‰§è¡Œæœ€ç»ˆå…¨é‡å¤‡ä»½"
              full_backup
              
              echo "ğŸ”„ è§¦å‘ç»­è·‘å·¥ä½œæµ"
              trigger_renew
              
              echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œé€€å‡ºå·¥ä½œæµ"
              exit 1
            fi
            
            sleep 30
          done

      # ========== æ­¥éª¤9ï¼šæœ€ç»ˆç¯å¢ƒæ¸…ç† ==========
      - name: Step 9 - Final Cleanup
        if: ${{ always() }}
        run: |
          echo "===== æœ€ç»ˆç¯å¢ƒæ¸…ç† ====="
          
          # ä¼˜é›…å¸è½½ WebDAV
          if mountpoint -q "$WEBDAV_MOUNT_POINT" 2>/dev/null; then
            echo "ğŸ”„ å¸è½½ WebDAV æŒ‚è½½ç‚¹..."
            timeout 30 fusermount3 -uz "$WEBDAV_MOUNT_POINT" 2>/dev/null || \
            sudo umount -l "$WEBDAV_MOUNT_POINT" 2>/dev/null || true
          fi
          
          # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
          sudo rm -rf /tmp/* /var/tmp/* /home/runner/.rclone.conf /tmp/rclone.log
          
          # ç§»é™¤è°ƒè¯•ç”¨æˆ·
          if id "roots" &>/dev/null; then
            echo "ğŸ‘¤ ç§»é™¤è°ƒè¯•ç”¨æˆ· roots"
            sudo userdel -r roots 2>/dev/null || true
          fi
          
          # æ¸…ç† sudoers é…ç½®
          sudo rm -f /etc/sudoers.d/runner
          
          # æ¸…ç† Docker èµ„æº
          sudo docker system prune -af --filter "until=1h" >/dev/null 2>&1 || true
          sudo docker volume prune -f --filter "until=1h" >/dev/null 2>&1 || true
          
          # é‡å¯ Docker æœåŠ¡ï¼ˆå®Œå…¨æ¸…ç†èµ„æºï¼‰
          sudo systemctl restart docker || true
          
          echo "âœ… æœ€ç»ˆæ¸…ç†å®Œæˆ"
