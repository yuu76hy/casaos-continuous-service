name: 1Panel-Docker-Snapshot-Backup-Restore
on:
  workflow_dispatch:
  repository_dispatch:
    types: [renew_1panel_snapshot]

jobs:
  snapshot-backup-restore:
    runs-on: ubuntu-24.04
    timeout-minutes: 360
    env:
      MAX_RUN_MINUTES: 360
      WEBDAV_SNAPSHOT_DIR: "/z/Ubu"
      CORE_BACKUP_DIRS: "/var/lib/docker /etc/docker /opt/1panel /usr/local/bin/1panel /etc/1panel /etc/systemd/system /DATA"
      EXCLUDE_RULES: >-
        --exclude=*.log --exclude=*.tmp --exclude=*.cache
        --exclude=/var/lib/docker/containers/*/*.log
        --exclude=/var/lib/docker/overlay2/*/tmp --exclude=/var/lib/docker/tmp
        --exclude=/DATA/tmp --exclude=/DATA/缓存 --exclude=/DATA/logs
        --exclude=/opt/1panel/logs --exclude=/opt/1panel/tmp
        --exclude=/var/log/1panel/* --exclude=/etc/systemd/system/*.wants
      WEBDAV_URL: ${{ secrets.WEBDAV_URL }}
      WEBDAV_USER: ${{ secrets.WEBDAV_USER }}
      WEBDAV_PASSWORD: ${{ secrets.WEBDAV_PASSWORD }}
      USER_PAT: ${{ secrets.USER_PAT }}
      TAILSCALE_AUTH_KEY: ${{ secrets.TAILSCALE_AUTH_KEY }}
      REPO: ${{ github.repository }}
      ROOTS_PASSWORD: ${{ secrets.ROOTS_PASSWORD }}

    steps:
      - name: 1. Env Initialization (Oversea Server)
        run: |
          set -e
          sudo mkdir -p /etc/systemd/system 2>/dev/null || true
          
          sudo mv /etc/apt/sources.list /etc/apt/sources.list.bak 2>/dev/null || true
          cat <<EOF | sudo tee /etc/apt/sources.list
          deb http://archive.ubuntu.com/ubuntu/ noble main restricted universe multiverse
          deb http://archive.ubuntu.com/ubuntu/ noble-updates main restricted universe multiverse
          deb http://archive.ubuntu.com/ubuntu/ noble-security main restricted universe multiverse
          deb http://archive.ubuntu.com/ubuntu/ noble-backports main restricted universe multiverse
          EOF
          
          sudo apt update -y && sudo apt install -y curl wget jq fuse3 tar gzip locales openssl dnsutils apt-transport-https ca-certificates gnupg lsb-release file
          sudo locale-gen zh_CN.UTF-8 && export LC_ALL=zh_CN.UTF-8 LANG=zh_CN.UTF-8
          
          curl -fsSL https://rclone.org/install.sh | sudo bash
          
          if grep -q "requiretty" /etc/sudoers 2>/dev/null; then
            sudo sed -i 's/^Defaults requiretty/#Defaults requiretty/' /etc/sudoers
          fi
          echo "runner ALL=(ALL) NOPASSWD: ALL" | sudo tee /etc/sudoers.d/runner
          sudo chmod 0440 /etc/sudoers.d/runner && sudo mkdir -p /DATA && sudo chmod 755 /DATA
          
          echo "✅ Check Network Connectivity..."
          curl -fsSL https://github.com >/dev/null 2>&1 || { echo "❌ Can't Connect to GitHub"; exit 1; }
          echo "✅ Env Initialization Completed"

      - name: 2. Create roots Admin User
        run: |
          set -e
          if ! id "roots" &>/dev/null; then
            sudo useradd -m -s /bin/bash roots
            echo "roots:${ROOTS_PASSWORD:-$(openssl rand -base64 12)}" | sudo chpasswd
            sudo usermod -aG sudo,docker roots
            echo "✅ roots User Created Successfully"
          else
            echo "ℹ️ roots User Exists, Skip"
          fi

      - name: 3. Configure WebDAV (Rclone)
        id: webdav-config
        run: |
          set -e
          if [ -z "$WEBDAV_URL" ] || [ -z "$WEBDAV_USER" ] || [ -z "$WEBDAV_PASSWORD" ]; then
            echo "❌ Missing WebDAV Credentials, Skip Backup/Restore"
            echo "webdav_available=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          ENCRYPTED_PASS=$(rclone obscure "$WEBDAV_PASSWORD")
          rclone config create mywebdav webdav url="$WEBDAV_URL" vendor="generic" user="$WEBDAV_USER" pass="$ENCRYPTED_PASS" --config /home/runner/.rclone.conf
          sudo chown runner:runner /home/runner/.rclone.conf && sudo chmod 600 /home/runner/.rclone.conf
          
          if ! rclone ls mywebdav:/ --config /home/runner/.rclone.conf >/dev/null 2>&1; then
            echo "❌ WebDAV Connection Failed"
            echo "webdav_available=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          
          # 清理目录末尾/ + 仅提取快照文件名（避免重复拼接）
          WEBDAV_SNAPSHOT_DIR_CLEAN=$(echo "$WEBDAV_SNAPSHOT_DIR" | sed 's/\/$//')
          LATEST_SNAPSHOT=$(rclone ls mywebdav:${WEBDAV_SNAPSHOT_DIR_CLEAN} --config /home/runner/.rclone.conf | grep "1panel-snapshot-.*.tar.gz" | awk -F '/' '{print $NF}' | sort -r | head -n1)
          
          if [ -n "$LATEST_SNAPSHOT" ]; then
            echo "latest_snapshot=${WEBDAV_SNAPSHOT_DIR_CLEAN}/${LATEST_SNAPSHOT}" >> "$GITHUB_OUTPUT"
            echo "✅ Latest Snapshot：$LATEST_SNAPSHOT"
          else
            echo "ℹ️ No Snapshot in WebDAV, Will Perform Fresh Install"
          fi
          echo "webdav_available=true" >> "$GITHUB_OUTPUT"
          echo "WEBDAV_SNAPSHOT_DIR_CLEAN=${WEBDAV_SNAPSHOT_DIR_CLEAN}" >> "$GITHUB_ENV"

      - name: 4. Restore Snapshot from WebDAV
        if: ${{ steps.webdav-config.outputs.webdav_available == 'true' && steps.webdav-config.outputs.latest_snapshot != '' }}
        id: restore
        run: |
          set -e
          SNAPSHOT_PATH=${{ steps.webdav-config.outputs.latest_snapshot }}
          echo "===== Restore Snapshot：$SNAPSHOT_PATH ====="
          
          sudo systemctl stop 1panel docker containerd 2>/dev/null || true
          sudo systemctl unmask docker.socket containerd.socket 2>/dev/null || true
          sudo pkill -9 docker containerd 1panel 2>/dev/null || true
          sync && sleep 3
          
          if ! rclone cat mywebdav:${SNAPSHOT_PATH} --config /home/runner/.rclone.conf | head -c 100 >/dev/null 2>&1; then
            echo "❌ Snapshot Corrupted"
            echo "restore_success=false" >> "$GITHUB_OUTPUT"
            exit 1
          fi
          
          TEMP_SNAPSHOT="/tmp/snapshot.tar.gz"
          rclone cat mywebdav:${SNAPSHOT_PATH} --config /home/runner/.rclone.conf > "$TEMP_SNAPSHOT"
          # 解压快照：保留权限/所有者，覆盖现有文件
          sudo tar -xzf "$TEMP_SNAPSHOT" -C / \
            --overwrite \
            --ignore-failed-read \
            -p \
            --same-owner
          rm -f "$TEMP_SNAPSHOT"
          
          # 核心修复：统一1Panel路径 + 修正systemd服务文件（解决203/EXEC基础问题）
          sudo rm -f /usr/bin/1panel
          sudo ln -s /usr/local/bin/1panel /usr/bin/1panel 2>/dev/null || true
          if [ -f "/etc/systemd/system/1panel.service" ]; then
            sudo sed -i 's|ExecStart=/usr/bin/1panel|ExecStart=/usr/local/bin/1panel|g' /etc/systemd/system/1panel.service
          fi
          
          # 重装Docker保证环境一致性
          sudo apt purge -y moby* containerd* runc* docker* -y || true
          sudo apt autoremove -y && sudo apt clean
          curl -fsSL https://get.docker.com | sudo bash
          
          # 删除远端旧快照和元数据
          rclone delete mywebdav:${SNAPSHOT_PATH} --config /home/runner/.rclone.conf
          rclone delete mywebdav:${WEBDAV_SNAPSHOT_DIR_CLEAN}/snapshot_meta.txt --config /home/runner/.rclone.conf
          
          echo "✅ Snapshot Restored Successfully"
          echo "restore_success=true" >> "$GITHUB_OUTPUT"

      - name: 5. Clean Residues (Restore Failed)
        if: ${{ steps.restore.outputs.restore_success != 'true' }}
        run: |
          set -e
          echo "===== Clean 1Panel/Docker Residues ====="
          sudo systemctl stop 1panel docker containerd 2>/dev/null || true
          sudo pkill -9 docker containerd 1panel 2>/dev/null || true
          sync && sleep 3
          
          if sudo docker info >/dev/null 2>&1; then
            sudo docker rm -f $(sudo docker ps -aq) 2>/dev/null || true
            sudo docker rmi -f $(sudo docker images -aq) 2>/dev/null || true
            sudo docker volume rm -f $(sudo docker volume ls -q) 2>/dev/null || true
          fi
          
          sudo apt purge -y docker* moby* containerd* runc* 1panel* -y || true
          sudo apt autoremove -y && sudo apt clean
          sudo rm -rf /opt/1panel /etc/1panel /usr/local/bin/1panel /usr/bin/1panel /var/lib/docker /etc/docker /var/lib/containerd /DATA/*
          echo "✅ Residues Cleaned Completed"

      - name: 6. Install Docker+1Panel (No Snapshot/Restore Failed)
        if: ${{ steps.restore.outputs.restore_success != 'true' }}
        run: |
          set -e
          echo "===== Install Official Docker ====="
          sudo apt purge -y docker* moby* containerd* runc* -y || true
          sudo apt autoremove -y && sudo apt clean
          curl -fsSL https://get.docker.com | sudo bash
          
          sudo usermod -aG docker runner
          sudo chmod 666 /var/run/docker.sock 2>/dev/null || true
          sudo systemctl enable --now docker.service containerd.service
          sleep 10
          
          if ! sudo systemctl is-active --quiet docker; then
            echo "❌ Docker Start Failed"
            exit 1
          fi
          echo "✅ Docker Installed Completed：$(docker -v)"
          
          echo "===== Install 1Panel ====="
          curl -fsSL https://resource.fit2cloud.com/1panel/package/quick_start.sh | sudo bash -
          # 安装后直接统一路径，避免后续203错误
          sudo rm -f /usr/bin/1panel
          sudo ln -s /usr/local/bin/1panel /usr/bin/1panel 2>/dev/null || true
          sleep 5
          if ! sudo systemctl is-active --quiet 1panel; then
            sudo 1panel repair
          fi
          echo "✅ 1Panel Installed Completed"

      - name: 7. Restart Services (Restore Success)
        if: ${{ steps.restore.outputs.restore_success == 'true' }}
        run: |
          set -e
          echo "===== Restart 1Panel/Docker Services ====="
          
          # 修复Docker/containerd服务状态
          for service in docker.service containerd.service; do
            if sudo systemctl list-unit-files --type=service | grep -q "$service"; then
              sudo systemctl reset-failed "$service" 2>/dev/null || true
            fi
          done
          sudo systemctl daemon-reload && sleep 15
          sudo systemctl enable --now containerd.service 2>/dev/null || true && sleep 3
          sudo systemctl enable --now docker.service 2>/dev/null || true && sleep 10
          
          # 彻底修复203/EXEC错误：路径+权限+架构+服务文件四重校验
          echo "===== Fix 1Panel EXEC 203 Error ====="
          # 1. 强制统一可执行文件路径
          sudo rm -f /usr/bin/1panel
          sudo ln -s /usr/local/bin/1panel /usr/bin/1panel 2>/dev/null || true
          # 2. 检查主程序是否存在，不存在则修复安装
          if [ ! -f "/usr/local/bin/1panel" ]; then
            echo "⚠️ /usr/local/bin/1panel not found, reinstall main program (keep data)"
            curl -fsSL https://resource.fit2cloud.com/1panel/package/quick_start.sh | sudo bash -s -- --repair
          else
            # 3. 修复可执行权限（双路径都赋权）
            echo "✅ Fix 1Panel execute permission"
            sudo chmod +x /usr/local/bin/1panel /usr/bin/1panel
            # 4. 强校验架构兼容性（x86_64 Runner不兼容ARM/AARCH64）
            PANEL_ARCH=$(file /usr/local/bin/1panel | grep -oE 'x86-64|ARM|aarch64')
            RUNNER_ARCH=$(uname -m)
            if [ "$PANEL_ARCH" != "x86-64" ] && [ "$RUNNER_ARCH" = "x86_64" ]; then
              echo "⚠️ 1Panel arch ($PANEL_ARCH) incompatible with runner ($RUNNER_ARCH), reinstall x86_64 version"
              sudo rm -f /usr/local/bin/1panel /usr/bin/1panel
              curl -fsSL https://resource.fit2cloud.com/1panel/package/quick_start.sh | sudo bash -s -- --repair
            fi
          fi
          
          # 修正并重载systemd服务文件
          if [ -f "/etc/systemd/system/1panel.service" ]; then
            sudo sed -i 's|ExecStart=/usr/bin/1panel|ExecStart=/usr/local/bin/1panel|g' /etc/systemd/system/1panel.service
          else
            echo "✅ Regenerate 1panel.service file"
            sudo 1panel repair 2>/dev/null || true
          fi
          sudo systemctl daemon-reload  # 必须重载，否则服务配置修改不生效
          sudo systemctl enable --now 1panel.service 2>/dev/null || true && sleep 10
          
          # 服务状态校验：带重试机制，提升容错性
          echo "===== Check Service Status ====="
          # 校验Docker状态
          if ! sudo systemctl is-active --quiet docker; then
            echo "❌ Docker Start Failed：$(sudo journalctl -xeu docker.service --no-pager | head -20)"
            exit 1
          fi
          # 1Panel多轮重试（解决启动延迟问题）
          panel_active=false
          for retry in {1..3}; do
            if sudo systemctl is-active --quiet 1panel; then
              panel_active=true
              break
            fi
            echo "ℹ️ 1Panel not active, retry $retry/3..."
            sudo systemctl restart 1panel
            sleep 5
          done
          # 最终兜底：重试失败则再次修复安装（保留数据）
          if [ "$panel_active" = "false" ]; then
            echo "⚠️ 1Panel start failed, final repair (keep DATA/opt/1panel)"
            curl -fsSL https://resource.fit2cloud.com/1panel/package/quick_start.sh | sudo bash -s -- --repair
            # 修复后再次统一路径
            sudo rm -f /usr/bin/1panel
            sudo ln -s /usr/local/bin/1panel /usr/bin/1panel
            sudo systemctl daemon-reload
            sleep 5
            if ! sudo systemctl is-active --quiet 1panel; then
              echo "❌ 1Panel Start Failed：$(sudo journalctl -xeu 1panel.service --no-pager | head -20)"
              exit 1
            fi
          fi
          echo "✅ All Services Restarted Successfully"

      - name: 8. Deploy Tailscale (Optional)
        run: |
          set -e 
          if [ -z "$TAILSCALE_AUTH_KEY" ]; then
            echo "⚠️ 缺少Tailscale授权密钥，跳过"
            exit 0 
          fi 
          curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/noble.noarmor.gpg | sudo tee /usr/share/keyrings/tailscale-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/tailscale-archive-keyring.gpg] https://pkgs.tailscale.com/stable/ubuntu noble main" | sudo tee /etc/apt/sources.list.d/tailscale.list
          sudo apt update -y && sudo apt install -y tailscale
          sudo tailscale up --authkey="$TAILSCALE_AUTH_KEY" --accept-routes --hostname="1panel-snapshot-${{ github.run_id }}"
          echo "✅ Tailscale IP：$(sudo tailscale ip -4)"

      - name: 9. Create Snapshot + Upload WebDAV + Trigger Renew
        if: ${{ steps.webdav-config.outputs.webdav_available == 'true' }}
        run: |
          set -e 
          start_time=$(date +%s) 
          RENEW_TRIGGERED=false 
          
          # 清理旧容器函数
          stop_old_containers() { 
            if sudo docker info >/dev/null 2>&1; then
              OLD_CONTAINERS=$(sudo docker ps -aq)
              if [ -n "$OLD_CONTAINERS" ]; then
                sudo docker rm -f $OLD_CONTAINERS && echo "✅ Old Containers Cleaned"
              else
                echo "ℹ️ No Old Containers"
              fi
            fi
          }
          
          # 触发续跑函数
          trigger_renew() {
            if [ -z "$USER_PAT" ] || [ -z "$REPO" ]; then
              echo "❌ Missing PAT/Repository Info"
              return 1
            fi
            stop_old_containers
            if curl -fsSL --fail -X POST \
              -H "Authorization: token $USER_PAT" \
              -H "Accept: application/vnd.github.v3+json" \
              -H "Content-Type: application/json" \
              "https://api.github.com/repos/$REPO/dispatches" \
              -d '{"event_type":"renew_1panel_snapshot"}'; then
              echo "✅ Renew Triggered Successfully"
              RENEW_TRIGGERED=true
            else
              return 1
            fi
          }
          
          # 创建快照并上传函数
          create_snapshot() {
            # 过滤有效备份路径
            VALID_DIRS=""
            for dir in $CORE_BACKUP_DIRS; do
              if [ -d "$dir" ] || [ -f "$dir" ]; then
                VALID_DIRS="$VALID_DIRS $dir"
              else
                echo "ℹ️ Skip Non-Existent Path：$dir"
              fi
            done
            if [ -z "$VALID_DIRS" ]; then
              echo "❌ No Valid Backup Paths"
              return 1
            fi
            
            # 定义快照文件名和路径
            SNAPSHOT_NAME="1panel-snapshot-$(date +%Y%m%d-%H%M%S).tar.gz"
            TMP_SNAPSHOT="/tmp/$SNAPSHOT_NAME"
            REMOTE_PATH="mywebdav:${WEBDAV_SNAPSHOT_DIR_CLEAN}/$SNAPSHOT_NAME"
            
            # 停止服务后创建快照
            sudo systemctl stop 1panel docker containerd 2>/dev/null || true
            sudo pkill -9 docker containerd 1panel 2>/dev/null || true
            sync && sleep 5
            
            # 打包快照：保留权限/ACL/扩展属性，应用排除规则
            sudo tar -czpf "$TMP_SNAPSHOT" \
              --ignore-failed-read \
              -p \
              --same-owner \
              --acls \
              --xattrs \
              --exclude='*.log' --exclude='*.tmp' --exclude='*.cache' \
              --exclude='/var/lib/docker/containers/*/*.log' \
              --exclude='/var/lib/docker/overlay2/*/tmp' --exclude='/var/lib/docker/tmp' \
              --exclude='/DATA/tmp' --exclude='/DATA/缓存' --exclude='/DATA/logs' \
              --exclude='/opt/1panel/logs' --exclude='/opt/1panel/tmp' \
              --exclude='/var/log/1panel/*' --exclude='/etc/systemd/system/*.wants' \
              $VALID_DIRS || { echo "❌ Tar Package Failed"; return 1; }
            
            # 校验快照有效性（避免空包）
            if [ $(stat -c%s "$TMP_SNAPSHOT") -lt 1024 ]; then
              echo "❌ Invalid Snapshot (File Too Small)"
              rm -f "$TMP_SNAPSHOT"
              return 1
            fi
            sudo chown runner:runner "$TMP_SNAPSHOT"
            
            # 上传快照到WebDAV
            if ! sudo -u runner rclone copy "$TMP_SNAPSHOT" "$REMOTE_PATH" --config /home/runner/.rclone.conf --transfers 4; then
              echo "❌ Upload Failed"
              rm -f "$TMP_SNAPSHOT"
              return 1
            fi
            
            # 生成并上传快照元数据
            printf "snapshot_name=%s\ncreate_time=%s\nsnapshot_size=%s\ndocker_version=%s\n1panel_version=%s\n" \
              "$SNAPSHOT_NAME" \
              "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
              "$(du -sh "$TMP_SNAPSHOT" | awk '{print $1}')" \
              "$(docker -v 2>/dev/null | awk '{print $3}' | sed 's/,//g')" \
              "$(1panel -v 2>/dev/null | awk '{print $3}' || echo 'unknown')" | sudo tee /tmp/snapshot_meta.txt
            sudo -u runner rclone copy /tmp/snapshot_meta.txt "mywebdav:${WEBDAV_SNAPSHOT_DIR_CLEAN}/snapshot_meta.txt" --config /home/runner/.rclone.conf
            
            # 清理临时文件并重启服务
            rm -f "$TMP_SNAPSHOT" /tmp/snapshot_meta.txt
            sudo systemctl start docker containerd 1panel 2>/dev/null || true
            echo "✅ Snapshot Created & Uploaded Successfully"
            return 0
          }
          
          # 主循环：运行2分钟后创建快照+触发续跑，超时自动退出
          while true; do
            run_mins=$(( ( $(date +%s) - start_time ) / 60 ))
            echo "⏱️ Running Time：$run_mins / $MAX_RUN_MINUTES Mins"
            
            if [ $run_mins -ge 2 ] && [ "$RENEW_TRIGGERED" = "false" ]; then
              create_snapshot && trigger_renew
            fi
            
            if [ $run_mins -ge $MAX_RUN_MINUTES ]; then
              echo "⏹️ Timeout, Exit"
              exit 0 
            fi 
            sleep 60 
          done

      - name: 10. Clean Temp Files (Always Execute)
        if: ${{ always() }} 
        run: |
          set -e 
          # 清理所有临时文件和配置
          sudo rm -rf /tmp/1panel-snapshot-*.tar.gz /home/runner/.rclone.conf /etc/sudoers.d/runner /tmp/rclone_*.log
          sudo systemctl unmask docker.socket containerd.socket 2>/dev/null || true
          # 清理软链接（可选，避免残留）
          sudo rm -f /usr/bin/1panel 2>/dev/null || true
          echo "✅ 临时文件清理完成"
